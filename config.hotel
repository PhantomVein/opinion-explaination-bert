[Data]
bert_dir = ../bert-base-uncased-model
data_dir = experiments/rst
train_file = %(data_dir)s/hotel_train.txt
dev_file = %(data_dir)s/hotel_dev.txt
test_file = %(data_dir)s/hotel_test.txt
pretrained_embeddings_file = %(data_dir)s/sgns.zhihu.bigram-char
min_occur_count = 0

[Save]
save_dir = experiments/rst_model
config_file = %(save_dir)s/config.cfg
save_model_path = %(save_dir)s/classify_model
save_vocab_path = %(save_dir)s/vocab
load_dir = experiments/rst_model
load_model_path = %(load_dir)s/model
load_vocab_path = %(load_dir)s/vocab

[Network]
lstm_layers = 2
word_dims = 768
dropout_emb = 0.5
lstm_hiddens = 128
dropout_lstm_input = 0.5
dropout_lstm_hidden = 0.5
hidden_size = 128
output_attentions = False
start_layer = 8
num_classes = 3
end_layer = 12

[Optimizer]
L2_REG = 0
learning_rate = 1e-3
beta_1 = .9
beta_2 = .999
epsilon = 1e-08
clip = 5.0
decay = 1
decay_steps = 10

[Run]
train_iters = 50000
bert_batch_size = 2
train_batch_size = 128
test_batch_size = 128
validate_every = 100
save_after = 10
update_every = 1
max_sentence_len = 128
